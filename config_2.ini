[GLOBALS]
n=10
count=800
number_of_batches=100
number_of_epoch=5
loss = cross_entropy
wreg = 0.001
wrt = L2

[INPUT_LAYER]
input = 100
[OUTPUT_LAYER]
size= 4
act= tanh 
wr= -1 1
lrate= 0.1
br= 0 0
b_lrate= 0
softmax = True